# Airflow

> Airflow is a platform to programmatically author, schedule and monitor workflows
>
> Source: [Airflow](https://airflow.apache.org)

Airflow can be used to:

- run tasks on a regular schedule
- run memory-intensive workloads
- run end-to-end processing workflows involving multiple steps and dependencies
- monitor the performance of workflows and identify issues

## Important links

- [Airflow dev UI](https://eu-west-1.console.aws.amazon.com/mwaa/home?region=eu-west-1#environments/dev/sso): for running and monitoring development and training workflows on the Airflow UI

- [Airflow prod UI](https://eu-west-1.console.aws.amazon.com/mwaa/home?region=eu-west-1#environments/prod/sso): for running and monitoring production workflows on the Airflow UI

- [Airflow Repo](https://github.com/moj-analytical-services/airflow): Github repo to store Airflow DAGs and roles

- [Airflow template for Python](https://github.com/moj-analytical-services/template-airflow-python): Github template repository for creating a Python image to run an Airflow pipeline

- [Airflow template for R](https://github.com/moj-analytical-services/template-airflow-r): Github template repository for creating an R image to run an Airflow pipeline

- [Airflow pipeline concepts](/tools/airflow/concepts)

- [Airflow Pipeline Instructions](/tools/airflow/instructions): Step by step guide for creating an example Airflow pipeline and related resources 

- [Troubleshooting Airflow Pipelines](/tools/airflow/troubleshooting)

- Support: contact the Data Engineering team on the #ask-data-engineering Slack channel
