# Airflow

> Airflow is a platform created by the community to programmatically author, schedule and monitor workflows
>
> Source: [Airflow](https://airflow.apache.org)

Airflow can be used to:

- run tasks on a regular schedule
- run tasks on a high-memory node
- run end-to-end processing workflows involving multiple steps and dependencies
- monitor the performance of workflows and identify issues

## Important Links

- [Airflow Dev UI](https://eu-west-1.console.aws.amazon.com/mwaa/home?region=eu-west-1#environments/dev/sso): For running and monitoring development/training worflows on the Airflow UI

- [Airflow Prod UI](https://eu-west-1.console.aws.amazon.com/mwaa/home?region=eu-west-1#environments/prod/sso): For running and monitoring production worflows on the Airflow UI

- [Airflow Repo](https://github.com/moj-analytical-services/airflow): Github repo to store Airflow DAGs and roles

- [Template Airflow Python](https://github.com/moj-analytical-services/template-airflow-python): Github template repository for creating a python image to run in Airflow pipeline

- [Template Airflow R](https://github.com/moj-analytical-services/template-airflow-r): Github template repository for creating an R image to run in Airflow pipeline

- [Airflow Pipeline Concepts](/data-engineering-tools/airflow/concepts)

- [Airflow Pipeline Instructions](/data-engineering-tools/airflow/instructions): Step by step guide for creating an example Airflow pipeline and related resources 

- [Troubleshooting Airflow Pipelines](/data-engineering-tools/airflow/troubleshooting)

- Support: contact the Data Engineering team on #ask-data-engineering Slack channel
